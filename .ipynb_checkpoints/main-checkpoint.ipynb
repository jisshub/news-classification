{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "# from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "STOPWORDS=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           authors       category       date  \\\n",
       "0  Melissa Jeltsen          CRIME 2018-05-26   \n",
       "1    Andy McDonald  ENTERTAINMENT 2018-05-26   \n",
       "2       Ron Dicker  ENTERTAINMENT 2018-05-26   \n",
       "3       Ron Dicker  ENTERTAINMENT 2018-05-26   \n",
       "4       Ron Dicker  ENTERTAINMENT 2018-05-26   \n",
       "\n",
       "                                            headline  \\\n",
       "0  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "\n",
       "                                   short_description  \n",
       "0  She left her husband. He killed their children...  \n",
       "1                           Of course it has a song.  \n",
       "2  The actor and his longtime girlfriend Anna Ebe...  \n",
       "3  The actor gives Dems an ass-kicking for not fi...  \n",
       "4  The \"Dietland\" actress said using the bags is ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df=pd.read_json('News_Category_Dataset.json',lines=True)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining some raw data categories that are very close\n",
    "news_df.category=news_df.category.map(lambda x:\"WORLDPOST\" if x==\"THE WORLDPOST\" else x)\n",
    "news_df.category=news_df.category.map(lambda y:\"ARTS & CULTURE\" if y==\"ARTS\" or y==\"ARTS & CULTURE\" else y)\n",
    "news_df.category=news_df.category.map(lambda z:\"EDUCATION\" if z==\"EDUCATION\" or z==\"COLLEGE\" else z)\n",
    "\n",
    "# removing rows with text size less than 10\n",
    "mask=news_df['short_description'].str.len()>20\n",
    "news_df=news_df.loc[mask]\n",
    "# combines headline and short_description for the input\n",
    "news_df['text']=news_df.headline+\" \"+news_df.short_description\n",
    "# replace empty values with NaN\n",
    "news_df=news_df.replace(\"\",np.NaN)\n",
    "# drop rows with value as NaN\n",
    "news_df.dropna(axis=0,inplace=True)\n",
    "\n",
    "# news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing bad symbols,stopwords from text and lemmatizing each words in the text. \n",
    "import re\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z +_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text=text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwords from text\n",
    "    text = ' '.join([lemmatizer.lemmatize(w) for w in text.split()])\n",
    "    return text\n",
    "    \n",
    "news_df['text'] = news_df['text'].apply(clean_text)\n",
    "news_df['text'] = news_df['text'].str.replace('\\d+','')\n",
    "# len(news_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>mass shooting texas last week  tv left husban...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>smith join diplo nicky jam  world cup official...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>hugh grant marries first time age  actor longt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>jim carrey blast castrato adam schiff democrat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>julianna margulies us donald trump poop bag pi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text  \\\n",
       "0          CRIME   mass shooting texas last week  tv left husban...   \n",
       "1  ENTERTAINMENT  smith join diplo nicky jam  world cup official...   \n",
       "2  ENTERTAINMENT  hugh grant marries first time age  actor longt...   \n",
       "3  ENTERTAINMENT  jim carrey blast castrato adam schiff democrat...   \n",
       "4  ENTERTAINMENT  julianna margulies us donald trump poop bag pi...   \n",
       "\n",
       "   category_id  \n",
       "0            0  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "col = ['category', 'text']\n",
    "# news_df = news_df.reindex(columns=col)\n",
    "\n",
    "\n",
    "news_df = news_df[col]\n",
    "news_df = news_df[pd.notnull(news_df['text'])]\n",
    "\n",
    "news_df.columns = ['category', 'text']\n",
    "news_df['category_id'] = news_df['category'].factorize()[0]\n",
    "category_id_df = news_df[['category', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'category']].values)\n",
    "# print(category_to_id)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df.set_index(\"category\")\n",
    "news_df = news_df.drop(['WORLD NEWS','IMPACT','QUEER VOICES','LATINO VOICES','BLACK VOICES','FIFTY',\n",
    "                        'WEIRD NEWS','ENTERTAINMENT','GREEN','GOOD NEWS','COMEDY','PARENTS','WOMEN',\n",
    "                       'POLITICS','MEDIA','HEALTHY LIVING'], axis=0)\n",
    "news_df=news_df.replace(\"\",np.NaN)\n",
    "# drop rows with value as NaN\n",
    "news_df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index, thus categry is added as acolumn and set a new index.\n",
    "news_df=news_df.reset_index(\"category\")\n",
    "# cat_list=news_df.category.tolist()\n",
    "# new_list=list(dict.fromkeys(cat_list))\n",
    "# new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WORLDPOST         3419\n",
       "BUSINESS          3059\n",
       "SPORTS            2891\n",
       "ARTS & CULTURE    2117\n",
       "RELIGION          1738\n",
       "TASTE             1735\n",
       "EDUCATION         1731\n",
       "CRIME             1643\n",
       "TRAVEL            1555\n",
       "STYLE             1221\n",
       "TECH               899\n",
       "SCIENCE            879\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the info about our news dataframe\n",
    "# news_df.describe()\n",
    "\n",
    "news_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22887, 13214)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf=TfidfVectorizer(sublinear_tf=True, min_df=5, encoding='latin-1', ngram_range=(1, 2))\n",
    "features=tfidf.fit_transform(news_df.text).toarray()\n",
    "labels=news_df.category_id\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id_df = news_df[['category', 'category_id']].sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'ARTS & CULTURE':\n",
      "  . Most correlated unigrams:\n",
      ". artist\n",
      ". art\n",
      "  . Most correlated bigrams:\n",
      ". stage door\n",
      ". first nighter\n",
      "# 'BUSINESS':\n",
      "  . Most correlated unigrams:\n",
      ". company\n",
      ". business\n",
      "  . Most correlated bigrams:\n",
      ". business qa\n",
      ". woman business\n",
      "# 'CRIME':\n",
      "  . Most correlated unigrams:\n",
      ". cop\n",
      ". police\n",
      "  . Most correlated bigrams:\n",
      ". police said\n",
      ". police say\n",
      "# 'EDUCATION':\n",
      "  . Most correlated unigrams:\n",
      ". college\n",
      ". student\n",
      "  . Most correlated bigrams:\n",
      ". college student\n",
      ". higher education\n",
      "# 'HEALTHY LIVING':\n",
      "  . Most correlated unigrams:\n",
      ". cancer\n",
      ". health\n",
      "  . Most correlated bigrams:\n",
      ". mental health\n",
      ". gps guide\n",
      "# 'MEDIA':\n",
      "  . Most correlated unigrams:\n",
      ". news\n",
      ". fox\n",
      "  . Most correlated bigrams:\n",
      ". donald trump\n",
      ". fox news\n",
      "# 'RELIGION':\n",
      "  . Most correlated unigrams:\n",
      ". pope\n",
      ". christian\n",
      "  . Most correlated bigrams:\n",
      ". pope francis\n",
      ". daily meditation\n",
      "# 'SCIENCE':\n",
      "  . Most correlated unigrams:\n",
      ". nasa\n",
      ". scientist\n",
      "  . Most correlated bigrams:\n",
      ". scientist say\n",
      ". solar system\n",
      "# 'SPORTS':\n",
      "  . Most correlated unigrams:\n",
      ". player\n",
      ". nfl\n",
      "  . Most correlated bigrams:\n",
      ". lebron james\n",
      ". super bowl\n",
      "# 'STYLE':\n",
      "  . Most correlated unigrams:\n",
      ". hair\n",
      ". fashion\n",
      "  . Most correlated bigrams:\n",
      ". red carpet\n",
      ". fashion week\n",
      "# 'TASTE':\n",
      "  . Most correlated unigrams:\n",
      ". delicious\n",
      ". recipe\n",
      "  . Most correlated bigrams:\n",
      ". ice cream\n",
      ". cooking cuff\n",
      "# 'TECH':\n",
      "  . Most correlated unigrams:\n",
      ". facebook\n",
      ". apple\n",
      "  . Most correlated bigrams:\n",
      ". social network\n",
      ". new iphone\n",
      "# 'TRAVEL':\n",
      "  . Most correlated unigrams:\n",
      ". traveler\n",
      ". travel\n",
      "  . Most correlated bigrams:\n",
      ". national park\n",
      ". looney front\n",
      "# 'WORLDPOST':\n",
      "  . Most correlated unigrams:\n",
      ". refugee\n",
      ". syria\n",
      "  . Most correlated bigrams:\n",
      ". islamic state\n",
      ". north korea\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "N=2\n",
    "for category,category_id in sorted(category_to_id.items()):\n",
    "    features_chi2 = chi2(features, labels == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}':\".format(category))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifier\n",
    "# Naive Bayes Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(news_df['text'],\n",
    "                                                    news_df['category'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SCIENCE']\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "print(clf.predict(count_vect.transform([\n",
    "'unusual asteroid could interstellar guest solar system supposed interstellar immigrant located near jupiter atypical orbit'\n",
    "])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model=LinearSVC()\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(\n",
    "    features, labels, news_df.index, test_size=0.33, random_state=0\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# conf_mat=confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "#             xticklabels=category_id_df.category.values, \n",
    "#             yticklabels=category_id_df.category.values)\n",
    "# plt.ylabel('Actual')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the classification report for each class and the accuracy score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(metrics.classification_report(y_test, y_pred,\n",
    "                                    target_names=news_df['category'].unique()))\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news_classifier",
   "language": "python",
   "name": "news_classifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
